package com.graph.metric;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.io.PrintStream;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Random;

public class Tools {
	
	// first dimension: dataset (0:Facebook, 1:Enron )
	// second dimension: metric (0:Clustering coefficient, 1:Modularity)
	// third dimension: epsilon = {0:1.0, 1:2.0, 2:3.0, 3:4.0, 4:5.0, 5:6.0, 6:7.0, 7:8.0}
	public static final double[][][] optimalPercentage = {
			{{0.7071, 0.8098, 0.8614, 0.8923, 0.9126, 0.9268, 0.9372, 0.9449}, {0.8064, 0.8758, 0.9071, 0.9225, 0.9279, 0.9259, 0.9188, 0.9080}},  // Facebook  (each row -> a dataset) 
			{{0.6929, 0.7927, 0.8460, 0.8792, 0.9016, 0.9175, 0.9291, 0.9379}, {0.6223, 0.7255, 0.7908, 0.8345, 0.8643, 0.8844, 0.8971, 0.9028}},  // Enron
			{{0.6929, 0.7927, 0.8460, 0.8792, 0.9016, 0.9175, 0.9291, 0.9379}, {0.7195, 0.8129, 0.8617, 0.8913, 0.9097, 0.9120, 0.9232, 0.9199}},  // AstroPh
			{{0.6929, 0.7927, 0.8460, 0.8792, 0.9016, 0.9175, 0.9291, 0.9379}, {0.7323, 0.8231, 0.8700, 0.8988, 0.9175, 0.9300, 0.9380, 0.9418}},  // .......  need to be updated
			
			{{0.6929, 0.7927, 0.8460, 0.8792, 0.9016, 0.9175, 0.9291, 0.9379}, {0.7323, 0.8231, 0.8700, 0.8988, 0.9175, 0.9300, 0.9380, 0.9418}},  // .......  need to be updated
			{{0.6929, 0.7927, 0.8460, 0.8792, 0.9016, 0.9175, 0.9291, 0.9379}, {0.9257, 0.9550, 0.9677, 0.9747, 0.9786, 0.9801, 0.9796, 0.9772}}   // Gplus
	};
	
	public static final String[] inputFilename = {
			"dataset/facebook_combined", 
			"dataset/Email-Enron", 
			"dataset/CA-AstroPh-transform", 												
			"dataset/Brightkite_edges", 
			"dataset/twitter_combined_transform", 
			"dataset/gplus_combined_transform"};
	public static final int[] inputFileUserNum = {4039, 36692, 18772, 58228, 81306, 107614};
	public static final int[] inputFileK1 = {9, 13, 12, 15, 16, 17};
	
	public static final double[][] allLCC = {
			{0.2, 0.5, 0.8, 0.6055},   // each row -> a dataset
			{0.2, 0.5, 0.8, 0.4970},
			{0.2, 0.5, 0.8, 0.6313},
			{0.2, 0.5, 0.8, 0.1723},
			{0.2, 0.5, 0.8, 0.5653},
			{0.2, 0.5, 0.8, 0.4901}
	};
	
	
	public static double getOneDegree(boolean[][] mat, int node){
		double degree = 0.0;
		for(int i=0; i<mat[0].length; i++)
			if(mat[node][i]==true && node!=i)
				degree++;
		return degree;
	}
	
	public static double[] getDegree(boolean[][] mat){
		int userNum = mat[0].length;
		double[] degree = new double[userNum];
		for(int i=0; i<userNum; i++)
			degree[i] = getOneDegree(mat, i);
		return degree;
	}
	
	//As for the perturbed matrix, edges of node itself are not included.
	//Therefore, the maximum total number of edges is 0.5*n*(n-1)
	public static double getEdges(boolean[][] mat){
		int userNum = mat[0].length;
		double[] degree = getDegree(mat);
		double edges = 0;
		for(int i=0; i<userNum; i++)
			edges += degree[i];
		return edges/2;
	}
	
	public static ArrayList<Integer> getNeighbors(boolean[][] mat, int node){
		ArrayList<Integer> neighbors = new ArrayList<Integer>();
		for(int i=0; i<mat[0].length; i++)
			if(mat[node][i]==true)
				neighbors.add(i);
		return neighbors;
	}
	
	
	public static void naiveAlignment(boolean[][] noisyMat){
		int userNum = noisyMat[0].length;
		for(int i=0; i<userNum; i++){
			for(int j=i+1; j<userNum; j++){
				if(noisyMat[i][j] != noisyMat[j][i]){
					noisyMat[i][j] = false;
					noisyMat[j][i] = false;
				}
			}
		}
	}
	
	
	// directly add Laplace noise to degree, with sensitivity=1
	public static double[] addLaplaceNoise_Degree(double[] degree, double ep){
		int userNum = degree.length;
		double[] noisyDegree = new double[userNum];
		for(int i=0; i<userNum; i++){	
			noisyDegree[i] = degree[i] + Tools.LaplaceDist(2.0, ep);
			if(noisyDegree[i]<1)
				noisyDegree[i] = 1;
			else if(noisyDegree[i]>userNum-1)
				noisyDegree[i] = userNum-1;			
		}
		return noisyDegree;
	}
	
	
	//noise generated by Laplace distribution
	public static double LaplaceDist(double sensitivity, double ep){
		double scale = sensitivity/ep;
		Random rng = new Random();
		double U = rng.nextDouble()-0.5; 
		return -scale*Math.signum(U)*Math.log(1-2*Math.abs(U));
	}
	
	
	public static double mergeTwoNoisyDegree(double v1, double r1, double v2, double r2){
		return v1*r2/(r1+r2) + v2*r1/(r1+r2);
	}
	
	public static double[] mergeTwoNoisyDegree_list(double[] v1, double r1, double[] v2, double[] r2){
		int userNum = v1.length;
		double[] noisyDegree = new double[userNum];
		for(int i=0; i<userNum; i++)
			noisyDegree[i] = mergeTwoNoisyDegree(v1[i], r1, v2[i], r2[i]);
		return noisyDegree;
	}
	
	public static double[] getVariance_list(double[] degree, double epsilon){
		double userNum = degree.length;
		double[] variance = new double[(int)userNum];
		double p = Math.exp(epsilon) / (1+Math.exp(epsilon));
		for(int i=0; i<userNum; i++)
			variance[i] = userNum * ( 1/(16*(p-0.5)*(p-0.5)) - (degree[i]/userNum-0.5)*(degree[i]/userNum-0.5) );
		return variance;
	}
	
	
	public static void writeClusterToFile(String fileName, ArrayList<HashSet<Integer>> clusters) throws IOException {  
        BufferedWriter bufferedWriter = new BufferedWriter(new FileWriter(fileName));  
        for (HashSet<Integer> set : clusters) {  
        	for(int v : set)
        		bufferedWriter.write(v+" ");  
            bufferedWriter.newLine();  
        }  
        bufferedWriter.close();  
    }
	
	
	public static ArrayList<HashSet<Integer>> readClusterFromFile(String filename) throws Exception{
		ArrayList<HashSet<Integer>> clusters = new ArrayList<HashSet<Integer>>();
		BufferedReader br = new BufferedReader(new FileReader(filename));
		String text = "";
		while((text = br.readLine()) != null){
			HashSet<Integer> hs = new HashSet<Integer>();
			String[] tokens = text.split(" ");
			for(int i=0; i<tokens.length; i++)
				hs.add(Integer.parseInt(tokens[i]));
			clusters.add(hs);
		}
		
		return clusters;
	}
	
	public static double[] readVectorFromFile(String filename, int userNum) throws Exception{
		BufferedReader br = new BufferedReader(new FileReader(filename));
		double[] vec = new double[userNum];
		for(int i=0; i<userNum; i++)
			vec[i] = Double.parseDouble(br.readLine());
		br.close();
		return vec;
	}
	
	
	public static void writeVectorToFile(String filename, double[] vec) throws Exception{
		PrintStream ps = new PrintStream(new File(filename));
		for(int i=0; i<vec.length; i++)
			ps.println(vec[i]);
		ps.close();
	}
	
	public static void writeGraphToFile(String filename, boolean[][] graph) throws Exception{
		PrintStream ps = new PrintStream(new File(filename));
		int userNum = graph[0].length;
		for(int i=0; i<userNum; i++){
			for(int j=i+1; j<userNum; j++){
				if(graph[i][j]==true)
					ps.println(i+"\t"+j);
			}
		}
		ps.close();
	}
	
	
	public static void generatContigencyTable(ArrayList<HashSet<Integer>> clusters1, ArrayList<HashSet<Integer>> clusters2, String method_path, int dataset, double epsilon) throws Exception{
		String filename = method_path+"_"+dataset+"_"+(int)epsilon+".csv";
		PrintStream ps = new PrintStream(new File(filename));
		
		int row = clusters1.size();
		int col = clusters2.size();
		for(int i=0; i<row; i++){
			HashSet<Integer> c1 = clusters1.get(i);
			for(int j=0; j<col; j++){
				HashSet<Integer> c2 = clusters2.get(j);
				HashSet<Integer> c = new HashSet<Integer>();
				for(int v : c2)
					c.add(v);
				c.retainAll(c1);
				if(j!=col-1)
					ps.print(c.size()+",");
				else
					ps.println(c.size());
			}
		}
		ps.close();
	}
	
	
	
	public static double getPopularDegree(double[] degree){
		int userNum = degree.length;
		double[] count = new double[userNum];
		for(int i=0; i<userNum; i++)
			count[(int)(degree[i])]++;
		double max = count[0];
		int maxIndex = 0;
		for(int i=0; i<userNum; i++){
			if(max<count[i]){
				max = count[i];
				maxIndex = i;
			}
		}
		System.out.println("max="+max);
		return maxIndex;
	}
		
}











